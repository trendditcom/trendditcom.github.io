---
title: "Workflows"
description: "
In this chapter Practitioners are going to develop a more ambitiously featured project. While Teams can continue to follow the guidance from Rails of Vibe C..."
author: "Trenddit Team"
publishedAt: "2025-07-05"
tags: ["ai", "automation", "development", "workflows", "productivity", "aws", "knowledge-management", "trenddit"]
---


In this chapter Practitioners are going to develop a more ambitiously featured project. While Teams can continue to follow the guidance from Rails of Vibe Coding, Teams can try some interesting variants to the vibe coding strategies.

I want to develop VibeFlow - a personal document management and workflow automation CLI app inspired by recently launched agent based CLI experiences including Anthropic Claude Code and OpenAI Codex.

## Prompting VibeFlow Product Definition

First variant from prior projects and vibe coding workflows is that during product definition phase Practitioners are opinionated about using minimal technical stack (Python), user experience (CLI), model and platform (Amazon Bedrock hosted Claude Sonnet), and agent protocol (MCP).

I use the following definition of VibeFlow project to prompt Claude Desktop and O4-mini-high in Deep Research mode.

Read [https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/introduction) to learn about MCP protocol, servers, and clients and related code examples in Python. Then study how a popular MCP client and server Claude Code has been designed by reading [https://gerred.github.io/building-an-agentic-system/index.html](https://gerred.github.io/building-an-agentic-system/index.html) and [https://docs.anthropic.com/en/docs/claude-code/overview](https://docs.anthropic.com/en/docs/claude-code/overview). 

Now ultrathink to create requirements, design, and technical specifications of a modern Command Line Interface user experience for a document and workflow automation tool called **VibeFlow**.

Just like Claude Code our product VibeFlow can be launched in a given folder, it comes pre-configured with relevant MCP servers from [https://modelcontextprotocol.io/examples](https://modelcontextprotocol.io/examples) and [https://github.com/punkpeye/awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers) lists for document management, content management, knowledge management, document search, online search, document generation, document editing, and document Q&A. 

It has a chat interface like Claude Code. It also has an Explorer interface to browse documents. It also has an interface to help define agent based workflows using various MCP tools at its disposal. 

The domains for these workflows are personal productivity including document management, planning, and task management. The specialized domains also include personal investment planning, work and educational research and report generation, and online shopping research, comparison, recommendations, and activities. 

Make sure the technology stack in based on Python. The CLI should run on a personal laptop. It should leverage Amazon Bedrock managed Claude Sonnet 3.7 model capabilities to its fullest to automate and integrate with all features of VibeFlow.


This approach aligns with Trenddit's mission to provide lean AI automation solutions. The Trenddit Memo browser extension exemplifies these principles by enabling knowledge workers to capture, organize, and interact with information using AI-powered automation.

For organizations looking to implement similar AI-driven workflows, consider how tools like Trenddit Memo can streamline knowledge management and enhance productivity across teams.

## Deep Research Requirements Specifications

My second variant, to the Rails of Vibe Coding, is to do deep research on the project design, requirements, specifications, and samples upfront before generating the first line of project code.

The O4-mini-high model responds with a well written narrative based requirements specifications.

![Image](./../images/spec-o4-mini-high.png)

This also includes a high level architecture diagram as part of the generated specification.

![Image](./../images/high-level-architecture.png)

Similarly here is the high level system architecture generated by Claude.

![Image](./../images/ascii-architecture.png)

I have noticed that Claude favors code generation over narrative based specifications. Most of its response is actual module by module code written to meet the requirements of the project.

![Image](./../images/code-sample.png)

At a high level I see OpenAI and Anthropic responses aligned on my product vision. I want to use both the responses in my project workflow.

So I convert the o4-mini-high Deep Research response to markdown and save it as `spec.md` file to indicate requirements specifications for the product. I use the Sonnet 3.7 reasoning response as `samples.md` to indicate code samples to refer in conjunction with the specifications.

I see several advantages in the approach so far. Deep Research of product specification and design upfront helps me think through the product and evaluate what the tech stack and code may look like upfront using one prompt instead of doing this incrementally over an extended set of vibe coding sessions. This is time and cost efficient. Comparing and combining deep research and reasoning responses of two competing frontier models is also helpful to combine strengths (reasoning narrative for OpenAI and code samples for Claude).

## Sprint Setup and Scaffold

Next variant to the Rails of Vibe Coding is that instead of creating a complete project plan upfront, I  intentionally extract sprints as feature-slices incrementally from the specifications and samples generated in prior section. This has several advantages. First, I make sure the specification, design, and samples are in context when creating each feature slice during project lifecycle. Second, Teams can iterate on results of a sprint in isolation and only move to the next feature slice when happy with the current sprint. Third, it is easier to pivot the features this way based on how the project evolves. Fourth, it is easier for organizations to evaluate one sprint plan than go over an entire project plan in one go. Fifth, Teams can guide the sprint level plan in a more granular manner based on industry experience with the prior sprints.



This creates a sprint plan like so. It includes goals, tasks, project structure, implementation steps, testing setup, documentation, acceptance criteria, and development instructions. Much more comprehensive guidance compared to earlier versions of plan steps.

---
**Environment Setup Sprint Plan**
### Overview
This sprint focuses on setting up the development environment and creating a minimal project scaffold for VibeFlow. We'll establish the required dependencies, project structure, and a "Hello World" application to verify the setup works correctly.

### Goals
- Set up a Python virtual environment
- Install required dependencies
- Create basic project structure
- Implement a minimal "Hello World" application
- Establish basic testing framework
- Document build, test, and run procedures

### Tasks

### 1. Environment Setup
- Create a Python virtual environment
- Install and configure required dependencies:
  - boto3 for AWS Bedrock integration
  - Click for CLI management
  - Rich for terminal formatting
  - PyYAML for configuration
  - aiohttp for MCP server communications
  - textual for terminal UI (optional for initial setup)
  - pytest for testing
### ...

---

## Generating Scaffold

Once Practitioners are happy with the sprint plan, I develop it with a simple prompt.



I notice that the generation of first sprint is relatively faster than my earlier vibe coding attempts, possibly due to minimalist stack and feature requirements at this stage.

![Image](./../images/code-generation-sprint-setup.png)
The project structure is relatively simple as expected. Code generation is end-to-end including Bedrock integration.


![Image](./../images/setup-todos.png)

The code generation todos are following the sprint plan including creation of README.md with evaluation guide.

## Evaluating Scaffold

Once the code generation is complete Practitioners are ready to evaluate the first sprint release. The feature-slice is fairly comprehensive including command line samples, init command, chat prototype, and testing AWS and Bedrock connectivity.

![Image](./../images/vibeflow-evaluate-sprint-001.png)

It works first time without any errors. I notice one issue where Claude Sonnet 3 model id is used instead of 3.7 which Practitioners are able to correct easily.

![Image](./../images/VibeAWS Book/vibe-workflow-images/vibeflow-evaluate-cli-001.png)
This is awesome! This is the first vibe coding project where Teams can create an end-to-end feature slice as first sprint using a simple prompt and it works first time! This is significant considering the ambitious product vision, requirements, and specification which I used as the context.


## Generating Sprints

Before I extract the next sprint feature-slice it is time to generate Claude memory using the `/init` command and commit all changes to git. I also restart Claude Code to reset the context and apply any recent updates to Claude Code.

I use the following generic sprint planning prompt and add a `/sprint` slash command to help reusing it during my vibe coding sessions. The prompt itself was created after iterating with Claude to improve the prompt based on expected outcome.

---
**Generic Sprint Planning Prompt**

Generate the next VibeFlow project sprint using this streamlined approach:

1. ANALYSIS PHASE:
   - Review files in /sprints folder to understand progression and numbering
   - Analyze @spec.md for remaining requirements
   - Review @samples.md for implementation patterns
   - Determine the next sprint number and logical feature focus

2. PLANNING PHASE:
   - Based on your analysis, draft a comprehensive sprint plan following test-driven development principles
   - Include all required sections:
     * Title with proper sprint number format (e.g., "Sprint 004: Feature Name")
     * Overview explaining purpose and context
     * Clear goals (3-5 bullet points)
     * Detailed tasks with test examples
     * Specific acceptance criteria
     * Development instructions
   - Ensure the sprint builds logically on previous work
   - Verify the sprint delivers actual user value

3. OUTPUT:
   - Save EXACTLY ONE file named '/sprints/[NUMBER]-[feature-name].md' where:
     * [NUMBER] is the three-digit sprint number (e.g., '003', '004')
     * [feature-name] briefly describes the focus area in kebab-case
   - Confirm the file meets project standards and requirements before saving

---





![Image](./../images/sprint-generation-with-subagents.png)

## Complete Feature Sprint

Once the sprint file is created Teams can instruct Claude Code to develop it. Claude Code codes the feature-slice and writes a suite of related tests.


![Image](./../images/feature-sprint-complete.png)

I update `README.md` with latest user evaluation guide.

The the first feature I evaluate is the interactive chat. Again, it works the first time, with streaming response, response time indication, model configuration, and estimated input tokens. Beautiful! 

Note that Practitioners are experimenting with Terminal UI look and feel outside the scope of this project and that is why this screen grab looks different from others.

![Image](./../images/chat-feature.png)
Here is session or chat history saving and recall feature in action. Simple and effective.

![Image](./../images/chat-sessions.png)
The CLI also supports in-chat slash commands like /save for saving the session, and /stats command.

![Image](./../images/chat-commands.png)
## Injecting Fixes and Features

I noted a couple of bugs with this release. The chat did not maintain context across turns. The sessions once saved did not load.

I also noted missing features like ability to delete sessions. I also did not like certain features like auto saving a session when user exits chat with CTRL+C.

Once I instructed Claude Code to fix these bugs and address the missing features, I created a slash command `/changes` to keep a record of these changes for future sprint generations.



This generated an interim sprint file with just the changes recorded.

![Image](./../images/changes.png)

Teams can now test the multi-turn conversation feature with session resume capability.

![Image](./../images/conversation-session-resume.png)
I also run all tests for the project and ensure any further fixes are in place to pass all tests. I rerun the `/changes` command to update the sprint changes file with the fixes.

![Image](./../images/pytest.png)

## Document Explorer

recommended workflows so far for next sprint looks like this and it is performing the best so far compared with the strategies used for prior chapters.

| Command   | Action                                                                    |
| --------- | ------------------------------------------------------------------------- |
| /sprint   | Extract the next sprint plan based on spec, samples, and earlier sprints. |
| /develop  | Develop the sprint @sprint-plan                                           |
| /commit   | Commit all untracked changes                                              |
| /test     | Run all tests and fix errors in code                                      |
| /commit   | Commit all untracked changes                                              |
| /evaluate | Update evaluation guide based on sprint features built and test fixes     |
| user      | Evaluate the CLI manually as a user                                       |
| debug     | Runtime errors or bugs to fix                                             |
| /changes  | Capture any changes since last sprint as sprint-changes file              |
| /commit   | Commit all untracked changes                                              |

Unlike prior attempts Practitioners are able to generate fairly complex end-to-end features using one iteration. Prior workflows either generated UI mocks or simpler features per iteration. The tests result in some regressions but get fixed in one attempt. Prior workflows took many attempts. The depth of product functionality is amazing thanks to deep research done upfront on the product specification, requirements, and samples. 

Practitioners are only in second feature sprint and already have fully functioning document explorer, chat, search, document-chat integration, CLI commands for chat and explorer, and much more.

Practitioners are now able to index and search my Obsidian folder with a single vibeflow command!
![Image](./../images/folder-indexing-search.png)
Teams can then pick a document to chat with and answer specific questions based on the document contents.
![Image](./../images/document-chat.png)
Teams can also explore folders and files using the CLI. This is pretty cool!

![Image](./../images/vibeflow-explore.png)

As VibeFlow is CLI it can seamlessly run with any IDE like VS Code. Teams can open VS Code Terminal and run VibeFlow to integrate with other editor capabilities.

Teams can now attach documents to existing chat context. Here Practitioners are browsing my Obsidian folder. Teams can drag drop any file next to `/document` slash command within vibeflow chat to get the file path argument. Now my context has entire document contents which Teams can work with using multi-turn conversation. Teams can compare the VibeFlow chat response with the existing file open in VS Code.

![Image](./../images/document-context-enhance.png)

## Refactoring Modules

I move on to the next sprint and generate code for Workflow Engine. However, Practitioners are noticing that some of the modules like `cli.py` are becoming very large. A good indicator of this happening without looking at all the modules is when I start getting `Too many requests` error calling the Bedrock API. Another indicator is when debugging cycles are getting longer and more iterative while involving same modules.

I know it is time to refactor these modules to smaller units for better vibe coding performance. I pause my evaluation of Workflow Engine by committing all changes. I then go ahead and inject a new sprint to create code metrics reporting.

Here is the resulting module metrics report. I note `cli.py` and `documents.py` are immediate targets for refactoring.


![Image](./../images/module-metrics.png)

The module summary snapshot will help when comparing after refactoring is done.

![Image](./../images/module-metrics-summary.png)

Test coverage report will help after refactoring to note how coverage has changed for new modules.

![Image](./../images/test-coverage.png)

I start with modularizing `cli.py` with the following prompt.



This results in a comprehensive sprint plan. Organizations benefit from this plan for several reasons including splitting `cli.py` into commands while organizing everything as a package. This increases the reusability of VibeFlow as a framework which developers may want to integrate into their own apps. I also like the focus on testing and ensuring existing functionality does not get impacted. Of course the days mentioned in the sprint plan are interesting. Vibe Coding will cut down this development to minutes. It will be fun to note how many minutes vs 11 days estimate per plan!

---
**Modularization Sprint Plan**

### Sprint 006: CLI Modularization

### Overview

The VibeFlow CLI module (`vibeflow/cli.py`) has grown significantly as we've added new features, resulting in a single file of over 1600 lines. This sprint aims to refactor and modularize the CLI implementation to improve maintainability, code organization, and facilitate future development without changing any current functionality.

### Current Issues

- The `cli.py` file currently contains 1600+ lines of code with multiple concerns mixed together
- The file handles diverse functionality including chat, document exploration, workflow management, and more
- Growing complexity makes it challenging to maintain and extend
- High cognitive load for developers working on specific CLI features
- Limited opportunity for parallel development

### Objectives

- Refactor the `cli.py` file into a modular structure
- Separate concerns into logical components
- Maintain 100% functional parity with the current implementation
- Improve code organization and discoverability
- Make future CLI extensions easier to implement
- Ensure all tests pass with the new structure

### Technical Approach

We'll implement a modular CLI architecture that maintains the current Click command structure while distributing implementation logic across multiple files:

1. Create a new `cli/` package structure
2. Split functionality into logical modules
3. Use a plugin-like approach for command registration
4. Maintain backward compatibility
5. Implement proper dependency injection

### Tasks Breakdown

### 1. Setup Package Structure (1 day)

- Create the directory structure for the CLI package:
  ```
  vibeflow/cli/
  ├── __init__.py        # Package initialization, exports public API
  ├── main.py            # Main entry point, command group setup
  ├── commands/          # Individual command implementations
  │   ├── __init__.py
  │   ├── chat.py
  │   ├── document.py
  │   ├── explore.py
  │   ├── init.py
  │   ├── search.py
  │   └── workflow.py
  ├── helpers/           # Helper functions and utilities
  │   ├── __init__.py
  │   ├── display.py     # Display and formatting utilities
  │   ├── prompts.py     # User interaction prompts
  │   └── command.py     # Command processing logic
  └── utils/             # Utility functions
      └── __init__.py
  ```

### 2. Create Base Infrastructure (1 day)

- Implement a base command registration system
- Implement shared utilities for command groups
- Create a centralized dependency injection system
- Setup common console functionality
- Implement shared state management

### 3. Extract Common Utilities (1 day)

- Move display functions (`show_welcome`, `show_version`, etc.) to `helpers/display.py`
- Move prompt utilities to `helpers/prompts.py`
- Extract result display logic to appropriate helper modules
- Implement shared error handling

### 4. Refactor Core Commands (3 days)

- Refactor each command into its own module:
  - `init` command → `commands/init.py`
  - `chat` command → `commands/chat.py`
  - `test-bedrock` command → `commands/bedrock.py`
  - `sessions` command → `commands/sessions.py`
  - `explore` command → `commands/explore.py`
  - `index` command → `commands/document.py`
  - `search` command → `commands/search.py`
  
### 5. Refactor Workflow Commands (2 days)

- Refactor workflow command group to `commands/workflow.py`
- Extract individual workflow subcommands to separate functions
- Implement proper communication between workflow subcommands

### 6. Update Main CLI Entry Point (1 day)

- Update `cli.py` to import and register commands from the new modules
- Ensure backward compatibility for all imports
- Maintain the same CLI API and behavior

### 7. Testing and Verification (2 days)

- Ensure all existing tests pass with the new structure
- Add tests for proper command registration
- Verify all functionality works as expected
- Test edge cases across command boundaries

### Success Criteria

1. All existing CLI functionality works exactly as before
2. No changes to user-facing behavior or command syntax
3. All tests pass successfully
4. Code organization improves reviewer understanding
5. Average file size is reduced to under 300 lines
6. Documentation is updated to reflect the new structure

### Testing Strategy

1. Run existing test suite against refactored code
2. Perform manual testing of all commands
3. Create integration tests for cross-command functionality
4. Verify backward compatibility with existing scripts
5. Test performance to ensure no degradation

### Implementation Notes

- We'll use Python's module system for organization while maintaining Click's command group structure
- Commands will be registered dynamically to the main CLI group
- Shared utilities will be factored out to minimize duplication
- We'll follow the principle of "high cohesion, loose coupling" throughout

### Future Considerations

This modularization enables several future improvements:
- Plugin system for third-party CLI extensions
- More granular command permissions
- Better command discoverability and help documentation
- Easier implementation of new features

---

Before I begin the refactoring I run all the project tests to note if there are any existing regressions.

![Image](./../images/tests-passing.png)

Now I restart Claude before taking on a long sprint plan. Restarting Claude Code also helps track cost, time to develop, and other stats for just this run. Always Be Measuring. 

Next I hit the `/develop` slash command to find the latest sprint and develop it. 

The 11 days worth sprint plan was vibe coded in 15 minutes for less than $10, impacting 3,500 lines of code changes. Boom!

![Image](./../images/cost-stats.png)

Once I reconfirm that all the tests are passing, I rerun the code metrics report to note the changes. The results are nothing short of magic! Average lines of code reduction is 95%. One monolithic file was broken into 17 modules.

![Image](./../images/modularization-metrics.png)


What is even more fun is while evaluating the existing features Teams can attach the modularization report into vibeflow chat and summarize it. Pretty neat!

![Image](./../images/modularization-summary.png)


**Sidebar:** This was not the first attempt at refactoring and modularization. I attempted an even more ambitious refactoring in one go which involved all of the modules in the project. Bad idea. The executing went on forever. I landed with many bugs, which resolved ultimately. However, the functionality of the app changes. New command structure was introduced. Many commands stopped working. It was a mess. Commit history and Sprints discipline saved the day for organizations. I simply prompted Claude to rollback the project to sprint before modularization. Clean restart. What worked the next time was focusing on one module refactoring at a time.

## Workflow Engine

This is by far the most interesting release based on Vibe Coding that I have done since last 6 months that it became a thing.

At the heart of the Workflow Engine is YAML (structured natural language like) based workflow definitions and template.

In VibeFlow, templates are workflow definitions stored in the /templates subdirectory that serve as starting points for new workflows. Regular workflows are in the main workflows directory and are directly executable, while templates provide reusable patterns that can be copied and customized. Templates aren't shown in the primary workflow list but appear in a separate "Template Workflows" section when listing workflows.

Here is a basic file processor workflow template which Teams can copy and edit to create a workflow definition on my favorite editor.

```yaml
name: file-processor
description: Read a file and process its content
version: "1.0"
steps:
  - name: read_file
    tool: local
    action: read_file
    parameters:
      path: "{file_path}"
    description: "Read content from specified file"
  
  - name: analyze
    tool: llm
    action: generate
    parameters:
      prompt: "Analyze the following text and provide a summary:\n\n${read_file}"
      temperature: 0.7
      max_tokens: 500
    description: "Use Claude to analyze the file content"

outputs:
  content: "${read_file}"
  summary: "${analyze}"
```


Here is the workflow wizard helping create a workflow definition from scratch.

![Image](./../images/workflow-wizard.png)

This ends up generating a workflow definition like so.

```yaml
created_at: 2025-05-21 07:05:37.758641
description: Read a file and process its content
modified_at: 2025-05-21 07:05:51.398422
name: file-processor
outputs:
  summary: ${analyze}
steps:
- action: read_file
  description: 'Local step: read_file'
  name: read_file
  parameters:
    path: '{file_path}'
  tool: local
- action: generate
  description: 'Llm step: generate'
  name: analyze
  parameters:
    max_tokens: 500
    prompt: Analyze the following text and provide a summary:\n\n${read_file}
    temperature: 0.7
  tool: llm
tags: []
version: '1.0'
```


Then Teams can run the workflow.

![Image](./../images/workflow-run.png)


In fact this feature is so involved that I had to seek Claude Code's help to write the next section following my writing style for this book!

![Image](./../images/documentation-steps.png)

It is worth reminding myself. I ensured that Best practices involve not read or write a single line of code when building VibeFlow, true to the spirit of vibe coding. VibeFlow is now nearly 4,000 lines of code, 90+ tests passing! Let's read how the most advanced feature is delivered using vibe coding.

## Mastering the VibeFlow Workflow Engine: From Novice to Power User

As I sit at my desk facing an ever-growing list of repetitive tasks, I find myself thinking: "There must be a better way." Traditional automation tools feel overwhelming—requiring coding knowledge I simply don't have. That's when I discovered VibeFlow's workflow engine, an elegant solution that bridges the gap between powerful automation and accessibility.

In this comprehensive guide, I'll walk you through my journey with VibeFlow's workflow engine. Whether you're a non-technical user looking to automate everyday tasks or a developer wanting to create sophisticated multi-step workflows, this article will equip you with everything you need to know.

### Understanding the VibeFlow Workflow Engine

The VibeFlow workflow engine is the heart of the platform's automation capabilities. Built during Sprint 004 of the project's development, this powerful system allows users to define sequences of steps that can be executed automatically, combining local operations, AI-powered generation, and document processing into seamless workflows.

### What Makes the VibeFlow Workflow Engine Special?

Unlike many automation tools that require extensive coding knowledge, VibeFlow workflows can be created through a user-friendly interactive wizard or by writing simple YAML files. Each workflow consists of a series of steps that are executed in sequence, with data flowing between them.

The engine supports several key features that make it exceptionally versatile:

- **Multiple Tool Types**: Local operations, AI-powered generation via Claude 3.7 Sonnet, and document operations
- **Variable Handling**: Pass data between steps using references like `${step_name}`
- **Conditional Execution**: Run steps only when specific conditions are met
- **Parameter Support**: Create workflows that can accept user-provided parameters at runtime
- **Template System**: Start with pre-built templates for common tasks

### Core Components

The workflow engine is built on several key components:

1. **WorkflowDefinition**: The overall structure that includes metadata, steps, and outputs
2. **WorkflowStep**: Individual operations within a workflow
3. **WorkflowEngine**: The execution engine that processes workflows
4. **CLI Interface**: Command-line tools for managing and running workflows

### Getting Started: A Non-Technical User's Guide

Let me walk you through how I got started with VibeFlow workflows as someone without technical expertise.

### Installing and Setting Up

First, I needed to install VibeFlow. I opened a Terminal window and ran the following commands:

```bash
# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies for development
pip install -e ".[dev]"

# Initialize VibeFlow
vibeflow init
```

After installation, I verified everything was working by checking the version:

```bash
vibeflow --version
```

### Exploring Available Workflows

My first step was to see what workflows were already available. In my terminal, I typed:

```bash
vibeflow workflow list
```

This displayed a nicely formatted table showing all available workflows, separated into user workflows (ones Teams can create) and template workflows (pre-built examples):


![Image](./../images/workflow-list.png)

### Running My First Workflow

I decided to try the simplest workflow first—the hello-world template. I ran:

```bash
vibeflow workflow run hello-world
```

The output showed:

```
Loading workflow: hello-world
Executing workflow: hello-world
A simple Hello World workflow example

Workflow completed successfully!

┌──────────────────┐
│     Results      │
├──────────────────┤
│ result: HELLO, W │
│ ORLD!            │
└──────────────────┘
```

Success! The workflow ran two steps: first generating the text "Hello, World!" and then transforming it to uppercase.

### Understanding a Workflow's Structure

To better understand what the workflow was doing, I examined its details:

```bash
vibeflow workflow info hello-world
```

This showed me:

```
┌─────────────────┐
│  hello-world    │
└─────────────────┘
Description: A simple Hello World workflow example
Version: 1.0

Steps:
Step 1: greeting (local: echo)
  Parameters:
    text: Hello, World!
Step 2: transform (local: uppercase)
  Parameters:
    input: ${greeting}

Outputs:
  result: ${transform}
```

Now I understood the flow: 
1. The first step ("greeting") used the "echo" action to output "Hello, World!"
2. The second step ("transform") took the output from the greeting step and converted it to uppercase
3. The workflow returned the transformed text as its result

### Creating My First Custom Workflow

After exploring the examples, I wanted to create my own workflow. I used the interactive wizard:

```bash
vibeflow workflow create
```

This launched a step-by-step guide that asked me about recommended workflows:

```
This wizard will guide you through creating a new workflow.
A workflow consists of steps that are executed in sequence.

Workflow name: daily-journal
Description: Create a daily journal entry with the current date

Step 1
Step tool type [local/llm/mcp]: local
Local action: echo
Text: # Journal Entry for {date}

Step name: header

Step 2
Add another step? [y/n]: y
Step tool type [local/llm/mcp]: llm
Prompt for Claude: Create a thoughtful journal entry prompt for today that encourages reflection on:
1. Three things I'm grateful for
2. One challenge I faced
3. One thing I'm looking forward to tomorrow
Temperature (0.0-1.0): 0.7
Max tokens: 500
Step name: prompt

Step 3
Add another step? [y/n]: y
Step tool type [local/llm/mcp]: local
Local action: write_file
File path: {output_path|journal-entry.md}
Content: ${header}

${prompt}
Step name: save_entry

Define workflow outputs?
Output name: journal_prompt
Output value: ${prompt}
Add another output? [y/n]: y
Output name: file_path
Output value: ${save_entry}
Add another output? [y/n]: n

Workflow Preview:
Name: daily-journal
Description: Create a daily journal entry with the current date
Steps: 3
  1. header (local: echo)
  2. prompt (llm: generate)
  3. save_entry (local: write_file)
Outputs:
  journal_prompt: ${prompt}
  file_path: ${save_entry}

Save workflow? [y/n]: y
Workflow saved successfully: ./.vibeflow/workflows/daily-journal.yaml
```

Now I had a custom workflow that:
1. Creates a header with the current date (which I'll provide as a parameter)
2. Uses Claude to generate a thoughtful journal prompt
3. Saves both to a markdown file

### Running a Workflow with Parameters

To run my new workflow with parameters:

```bash
vibeflow workflow run daily-journal -p date="May 21, 2025" -p output_path="my-journal.md"
```

After executing, the workflow created a markdown file with a journal prompt tailored to that day, ready for organizations to fill in. The power of AI-assisted journaling without any coding!

### Advanced Features for Developers

As I became more comfortable with workflows, I started exploring more advanced features that developers would appreciate.

### Workflow Definition Structure

Each workflow is defined by a YAML file with the following structure:

```yaml
name: workflow-name
description: "Description of what this workflow does"
version: "1.0"
steps:
  - name: step1
    tool: local|llm|mcp
    action: action_name
    parameters:
      param1: value1
      param2: value2
    description: "Description of this step"
    condition: "optional_condition_to_evaluate"
outputs:
  output1: "${step1}"
  output2: "${step2}" 
tags: ["tag1", "tag2"]  # optional categorization
```

### Supported Tool Types

The engine supports three main tool types:

| Tool Type | Description | Example Actions |
|-----------|-------------|-----------------|
| `local` | Local file and text operations | echo, read_file, write_file, uppercase, lowercase, replace_text |
| `llm` | AI-powered text generation using Claude | generate (with prompts, temperature, etc.) |
| `mcp` | Model Context Protocol operations | list_documents, search_documents, get_document_content |

### Parameter Handling

Parameters in workflows can be:

1. **Runtime Parameters**: Values provided when running the workflow, using the syntax `{parameter_name}`
2. **Default Values**: Fallback when parameters aren't provided, using `{parameter_name|default_value}`
3. **Step References**: Values from previous steps, using `${step_name}`
4. **Nested References**: Access structured data using `${step_name.property.subproperty}`

### Conditional Execution

For more complex workflows, Teams can use conditions to control which steps run:

```yaml
steps:
  - name: detect_type
    tool: llm
    action: generate
    parameters:
      prompt: "Analyze this text and return only one word: either 'formal' or 'informal'"
      
  - name: formal_response
    tool: llm
    action: generate
    condition: "detect_type.strip().lower() == 'formal'"
    parameters:
      prompt: "Generate a formal business response to this inquiry"
      
  - name: informal_response
    tool: llm
    action: generate
    condition: "detect_type.strip().lower() == 'informal'"
    parameters:
      prompt: "Generate a friendly, conversational response to this message"
```

This workflow uses Claude to analyze the tone of a message and then generates an appropriate response based on whether it's formal or informal.

### Creating Complex Document Processing Pipelines

One of my favorite uses for workflows is creating document processing pipelines. Here's an example of a document analysis workflow:

```yaml
name: document-analysis
description: Analyze document content using Claude via Bedrock
steps:
  - name: read_document
    tool: local
    action: read_file
    parameters:
      path: "{document_path}"
      
  - name: extract_metadata
    tool: llm
    action: generate
    parameters:
      prompt: |
        Extract the following metadata from this document:
        - Title
        - Author (if available)
        - Date (if available)
        - Category/Topic
        
        Format the result as JSON. Document:
        
        ${read_document}
      temperature: 0.2
      
  - name: summarize
    tool: llm
    action: generate
    parameters:
      prompt: |
        Provide a concise summary of the following document in 2-3 paragraphs:
        
        ${read_document}
      temperature: 0.7
      
  - name: key_points
    tool: llm
    action: generate
    parameters:
      prompt: |
        Extract 5-7 key points from this document:
        
        ${read_document}
        
        Format as a bullet list.
      temperature: 0.4
      
  - name: generate_report
    tool: local
    action: write_file
    parameters:
      path: "{output_path|analysis-report.md}"
      content: |
        # Document Analysis Report
        
        ## Metadata
        ${extract_metadata}
        
        ## Summary
        ${summarize}
        
        ## Key Points
        ${key_points}
        
        ---
        *Report generated by VibeFlow*
        
outputs:
  metadata: "${extract_metadata}"
  summary: "${summarize}"
  key_points: "${key_points}"
  report_path: "${generate_report}"
```

This workflow:
1. Reads a document from a user-specified path
2. Uses Claude to extract metadata in structured JSON format
3. Generates a concise summary
4. Extracts key points as a bullet list
5. Combines everything into a comprehensive report

### Real-World Use Cases

Through industry experience with VibeFlow's workflow engine, I've discovered many practical applications. Here are some that have been particularly useful:

### 1. Content Generation and Transformation

- **Blog Post Generator**: Create first drafts of blog posts from topic ideas
- **Format Converter**: Convert content between formats (Markdown, HTML, etc.)
- **Translation Pipeline**: Translate documents while preserving formatting

### 2. Document Analysis

- **Research Paper Analyzer**: Extract methodology, findings, and limitations from academic papers
- **Contract Reviewer**: Identify key terms, obligations, and potential issues in legal documents
- **Report Summarizer**: Generate executive summaries of lengthy reports

### 3. Data Processing

- **Log Analysis**: Process log files to extract patterns and anomalies
- **CSV Transformer**: Clean and transform CSV data before import
- **Data Extraction**: Extract structured data from unstructured text

### 4. Task Automation

- **Daily Standup Generator**: Create daily status reports from project notes
- **Meeting Summarizer**: Process meeting transcripts into action items
- **Social Media Content Scheduler**: Generate variations of social posts from a single prompt

### Tips and Best Practices

Through trial and error, I've discovered some best practices for creating effective workflows:

### Breaking Down Complex Tasks

I've learned to break complex workflows into smaller, more manageable steps. This makes them:
- Easier to debug when something goes wrong
- More reusable as components in other workflows
- Clearer to understand when revisiting later

### Parameter Management

When creating workflows that will be used repeatedly:
- Use meaningful parameter names that clearly indicate purpose
- Provide sensible defaults for optional parameters
- Add descriptions in the workflow to document expected parameter formats

### Effective AI Prompting

For steps that use Claude, I've found these prompting techniques effective:
- Be specific about the expected format of output
- Use temperature settings appropriate to the task (lower for factual tasks, higher for creative ones)
- Include context from previous steps to build coherent outputs

### Error Handling

To make workflows more robust:
- Use conditional steps to validate inputs before processing
- Add validation steps for critical data
- Create fallback paths for when steps fail

### Understanding the Model Context Protocol (MCP) Integration

A powerful feature of VibeFlow's workflow engine is its integration with the Model Context Protocol (MCP), which allows AI models to interact with external tools and data sources. Let me explain how this works and how you can leverage it in your workflows.

### What is Model Context Protocol (MCP)?

The Model Context Protocol (MCP) is a standardized way for AI language models to interact with external tools and services. It allows models like Claude 3.7 Sonnet to:

1. Discover available tools and their capabilities
2. Make function calls to these tools
3. Process the results and incorporate them into responses

This enables the model to perform actions beyond simple text generation, such as searching and retrieving document content, analyzing data, and more.

### How VibeFlow Uses MCP

VibeFlow operates as an MCP client, providing Claude with access to various tool functionalities. When you use the `mcp` tool type in your workflows, you're leveraging this capability.

### MCP Servers in VibeFlow

VibeFlow implements its own custom MCP clients rather than using external ones. Currently, VibeFlow includes:

1. **Document Operations MCP Client**
   - Functions: list_documents, search_documents, get_document, get_document_content, index_file, index_directory
   - Use cases: Document retrieval, search, and indexing operations

The document operations MCP client allows Claude to interact with VibeFlow's document management system, making it possible to create workflows that search through documents, extract content, and generate insights based on document data.

VibeFlow's MCP implementation follows the official Model Context Protocol specification. For more information about the protocol and available server implementations, you can visit:
- [Model Context Protocol Official Site](https://modelcontextprotocol.io/)
- [MCP Examples](https://modelcontextprotocol.io/examples)
- [Awesome MCP Servers Repository](https://github.com/punkpeye/awesome-mcp-servers)

### Example MCP Workflow

Here's an example of a workflow that uses MCP to search documents and generate a report:

```yaml
name: document-research
description: Search documents for a topic and generate a research summary
steps:
  - name: search_docs
    tool: mcp
    action: search_documents
    parameters:
      query: "{search_topic}"
      limit: 5
    
  - name: extract_content
    tool: mcp
    action: get_document_content
    parameters:
      doc_id: "${search_docs.documents[0].id}"
    
  - name: generate_summary
    tool: llm
    action: generate
    parameters:
      prompt: |
        Based on the following document content, create a research summary about {search_topic}.
        
        Document content:
        ${extract_content.content.text}
      temperature: 0.4
      
outputs:
  summary: "${generate_summary}"
  searched_documents: "${search_docs.documents}"
```

This workflow:
1. Searches documents for a user-provided topic
2. Retrieves the content of the top search result
3. Uses Claude to generate a summary based on that content

### Extending VibeFlow with Custom MCP Servers

As a developer, you can extend VibeFlow by creating custom MCP servers to expose additional functionality to Claude and your workflows.

### Step 1: Create a custom MCP client class

Create a new class that inherits from `MCPClient` in the `vibeflow/mcp.py` module:

```python
class CustomServiceMCP(MCPClient):
    """MCP client for custom service operations."""
    
    def get_functions(self) -> List[Dict[str, Any]]:
        """Define available functions for this MCP client."""
        return [
            self.build_function_spec(
                name="custom_function",
                description="Description of what this function does",
                parameters={
                    "type": "object",
                    "properties": {
                        "param1": {
                            "type": "string",
                            "description": "Description of parameter 1"
                        },
                        "param2": {
                            "type": "integer",
                            "description": "Description of parameter 2"
                        }
                    },
                    "required": ["param1"]
                }
            ),
            # Add more function specifications as needed
        ]
    
    def handle_function_call(self, function_name: str, 
                           parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Handle function calls to this MCP client."""
        try:
            if function_name == "custom_function":
                # Implement function logic here
                param1 = parameters.get("param1")
                param2 = parameters.get("param2", 0)
                
                # Process parameters and generate result
                result = f"Processed {param1} with value {param2}"
                
                return {
                    "success": True,
                    "result": result
                }
            else:
                return {
                    "success": False,
                    "error": f"Unknown function: {function_name}"
                }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
```

### Step 2: Register your MCP client in the core module

Modify the `initialize_mcp_clients` method in the `VibeFlowCore` class to include your custom MCP client:

```python
def initialize_mcp_clients(self) -> None:
    """Initialize Model Context Protocol clients."""
    # Initialize document operations MCP client
    self.mcp_clients["document_operations"] = DocumentOperationsMCP(self)
    
    # Initialize your custom MCP client
    self.mcp_clients["custom_service"] = CustomServiceMCP(self)
```

### Step 3: Update the workflow engine to use your client

Modify the `_execute_mcp_step` method in the `WorkflowEngine` class to recognize your custom client type:

```python
def _execute_mcp_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
    """Execute an MCP step invoking Model Context Protocol."""
    # ...existing code...
    
    # Determine which MCP client to use based on action
    action = step.action
    
    # Map actions to client types
    if action.startswith("custom_"):
        client_type = "custom_service"
    else:
        client_type = "document_operations"  # Default
    
    # ...rest of the existing code...
```

### Step 4: Use your custom MCP client in workflows

Now you can create workflows that use your custom MCP functions:

```yaml
name: custom-workflow
description: A workflow using custom MCP functions
steps:
  - name: custom_step
    tool: mcp
    action: custom_function
    parameters:
      param1: "Hello from custom MCP!"
      param2: 42
  
  - name: process_result
    tool: local
    action: echo
    parameters:
      text: "Result: ${custom_step.result}"
```

### Integrating with External MCP Servers

VibeFlow can be extended to integrate with external MCP servers. Here's how you can connect VibeFlow to third-party MCP implementations:

1. **Install the External MCP Server**: Many MCP servers are available as Python packages or Docker containers

2. **Create a Bridge MCP Client**: Develop a client class that connects to the external server:

```python
class ExternalMCPBridge(MCPClient):
    """Bridge to an external MCP server."""
    
    def __init__(self, core, server_url="http://localhost:8000"):
        super().__init__(core)
        self.server_url = server_url
        
    def get_functions(self) -> List[Dict[str, Any]]:
        """Fetch available functions from the external MCP server."""
        # Make a request to the external server's functions endpoint
        response = requests.get(f"{self.server_url}/functions")
        functions = response.json()
        return functions
    
    def handle_function_call(self, function_name: str, 
                           parameters: Dict[str, Any]) -> Dict[str, Any]:
        """Forward function calls to the external MCP server."""
        try:
            # Make a request to the external server's execute endpoint
            response = requests.post(
                f"{self.server_url}/execute",
                json={"function": function_name, "parameters": parameters}
            )
            return response.json()
        except Exception as e:
            return {
                "success": False,
                "error": f"External MCP server error: {str(e)}"
            }
```

3. **Register the Bridge Client**: Add your bridge client to the MCP clients dictionary

4. **Configure Workflow Steps**: Use the new capabilities in your workflows

### Notable External MCP Servers

Here are some third-party MCP servers you can integrate with VibeFlow to extend its capabilities:

1. **Playwright MCP Server (Microsoft)** - Enables AI interaction with web pages via accessibility snapshots, supporting automated web testing, data extraction, and form completion

2. **AWS MCP Server** - Executes AWS CLI commands in a secure Docker environment, providing enhanced AWS service management beyond Bedrock

3. **Supabase MCP Server** - Provides SQL query execution and database exploration capabilities for integrating database operations into VibeFlow workflows

4. **Chroma MCP Server** - Vector database access for enhanced retrieval capabilities, working with both local and cloud Chroma instances

5. **Memory Server** - Knowledge graph-based persistent memory system for contextual information storage and retrieval, enabling persistent workflow state management

For a comprehensive list of available MCP servers, visit the [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers) repository.

### Extending the Workflow Engine

As a developer, I've also explored ways to extend the workflow engine with custom functionality:

### Creating Custom Local Actions

The workflow engine can be extended with custom local actions by modifying the `_execute_local_step` method in `workflows.py`. For example, to add a new action that counts words in text:

```python
elif action == "count_words":
    text = params.get("text", "")
    words = len(text.split())
    return words
```

### Integrating with External APIs

While not built directly into the current version, workflows can be extended to call external APIs by adding new tool types or local actions that make HTTP requests.

### Conclusion

The VibeFlow workflow engine has transformed how I approach repetitive tasks and complex document processing. From simple personal automations to sophisticated multi-step pipelines, the flexibility of the system means I'm constantly finding new ways to save time and improve consistency.

For non-technical users, the interactive wizard provides an accessible entry point to automation without requiring coding skills. For developers, the structured YAML format and extensible architecture offer a powerful foundation for creating complex workflow systems.

As AI continues to evolve, tools like VibeFlow's workflow engine represent a new paradigm of human-AI collaboration—where we define the processes and goals, while AI handles the execution. I'm excited to see how this approach will continue to develop and what new possibilities it will unlock.

Whether you're looking to streamline your daily tasks or build powerful automation systems, I hope this guide helps you harness the full potential of VibeFlow's workflow engine.



## Automation Best Practices

Industry leaders recommend a phased approach to AI automation implementation. [MIT Technology Review's automation guide](https://www.technologyreview.com/tag/automation/) emphasizes the importance of starting with well-defined, repeatable processes before expanding to more complex workflows.

[Harvard Business Review's research on workplace automation](https://hbr.org/topic/subject/automation) highlights that successful implementations focus on augmenting human capabilities rather than replacement, aligning with Trenddit's approach to lean AI automation.